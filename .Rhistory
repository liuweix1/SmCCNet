predError <- cbind(predError, dCorT[ , 4])
}
S1 <- rowMeans(testCC)
S2 <- rowMeans(predError)
T12 <- dCorT[ , -2]; T12[ , 2] <- S1; T12[ , 3] <- S2
utils::write.csv(T12, file = paste0(saveD, SCCAmethod, "CVmeanDeltaCors.csv"))
print(paste0("testCC choice: ", which(S1 == min(S1))))
print(paste0("CC Pred. Error choice: ", which(S2 == min(S2))))
}
hybrid_score = function(X, A, is_alpha = TRUE, npc=1){
#X: data matrix (n, p)
#A: corresponding adjacency matrix
#pc_id: PC index
g = igraph::graph_from_adjacency_matrix(A, mode = "undirected", weighted = TRUE, diag = FALSE)
# laplacian
L2 <- igraph::graph_from_adjacency_matrix(A, mode = "undirected", weighted = TRUE,diag = FALSE)
L2 <- as.matrix(igraph::graph.laplacian(L2, normalized = F))
# TOM
TOM_A = WGCNA::TOMsimilarity(as.matrix(A), verbose = FALSE)
alpha = igraph::graph.density(g)
X= scale(X, center = TRUE, scale = TRUE)
# weighted approach
if (is_alpha == TRUE)
temp  = (1-alpha)*(X %*% L2) + alpha*(X %*% TOM_A)
else
temp = (X %*% L2)
temp = summary(stats::prcomp(temp))
h_score = temp$x[,1:npc]
importance = temp$importance[,1:npc]
loading = temp$rotation[,1:npc]
return(list(h_score, importance, loading))
}
# (INTERNAL)
getCCAout <- function(X1, X2, Trait, Lambda1, Lambda2, CCcoef = NULL,
NoTrait = FALSE, FilterByTrait = FALSE, trace = FALSE){
# Compute CCA weights.
#
# X1: An n by p1 mRNA expression matrix.
# X2: An n by p2 miRNA expression matrix.
# Trait: An n by k trait data for the same samples (k >=1).
# Lambda1, Lambda2: LASSO pentalty parameters, need to be between 0 and 1.
# CCcoef: A 3 by 1 vector indicating weights for each pairwise canonical
#   correlation.
# NoTrait: Logical. Whether trait information is provided.
# FilterByTrait: Logical. Whether only the features with highest correlation
#   to Trait will be assigned nonzero weights. The top 80% features are reserved.
# trace: Logical. Whether to display CCA algorithm trace.
if(abs(Lambda1 - 0.5) > 0.5){
stop("Invalid penalty parameter. Lambda1 needs to be between zero and
one.")}
if(abs(Lambda2 - 0.5) > 0.5){
stop("Invalid penalty parameter. Lambda2 needs to be between zero and
one.")}
if(min(Lambda1, Lambda2) == 0){
stop("Invalid penalty parameter. Both Lambda1 and Lambda2 has to be
greater than 0.")
}
k <- ncol(Trait)
if(NoTrait | is.null(k)){
out <- PMA::CCA(X1, X2, typex = "standard", typez = "standard",
penaltyx = Lambda1, penaltyz = Lambda2, K = 1,
trace = trace)
}else{
if(FilterByTrait){
if(k > 1){
stop("'FilterByTrait == TRUE' only allows one trait at a time.")
}else{
out <- PMA::CCA(X1, X2, outcome = "quantitative", y = Trait,
typex = "standard", typez = "standard",
penaltyx = Lambda1, penaltyz = Lambda2, K = 1,
trace = trace)
}
}else{
xlist <- list(x1 = X1, x2 = X2, y = scale(Trait))
L1 <- max(1, sqrt(ncol(X1)) * Lambda1)
L2 <- max(1, sqrt(ncol(X2)) * Lambda2)
out <- myMultiCCA(xlist, penalty = c(L1, L2, sqrt(ncol(Trait))),
CCcoef = CCcoef, trace = trace)
out$u <- out$ws[[1]]; out$v <- out$ws[[2]]
}
}
return(out)
}
RobustPseudoWeights_MultiblockPLS <- function(X, Y, Between_Discriminate_Ratio = c(1,1),
SubsamplingPercent = NULL, CCcoef = NULL, LambdaBetween, LambdaPheno,
SubsamplingNum = 1000, ncomp_pls = 3)
{
# run between-omics SmCCA
BetweenOmicsWeight <- getRobustPseudoWeights_Multi(X, Trait = NULL, NoTrait = TRUE, CCcoef = CCcoef,
Lambda = LambdaBetween, s = SubsamplingPercent, SubsamplingNum = SubsamplingNum)
# column bind all data
X_all <- rlist::list.cbind(X)
# Feature type index
type_index <- unlist(purrr::map(1:length(X), function(h){
rep(h, ncol(X[[h]]))
}))
# create empty matrix to store the omics-phenotype weight
OmicsPhenoWeight <- matrix(0, nrow = nrow(BetweenOmicsWeight), ncol = ncol(BetweenOmicsWeight))
# run omics-phenotype PLS
for (i in 1:ncol(BetweenOmicsWeight))
{
# subset selected features
X_subset <- X_all[ ,which(BetweenOmicsWeight[,i] != 0)]
# run omics-phenotype SmCCA based on selected molecular features
Ws_pheno <- getRobustPseudoWeight_binary(X1 = X_subset, Trait = as.matrix(Y), Lambda1 = LambdaPheno,
s1 = 1, SubsamplingNum = 1, K = ncomp_pls)
# store weight
OmicsPhenoWeight[which(BetweenOmicsWeight[,i] != 0),i] <- Ws_pheno
# normalize each data type
for (j in 1:length(X))
{
OmicsPhenoWeight[which(type_index == j),i] <- OmicsPhenoWeight[which(type_index == j),i]/pracma::Norm(OmicsPhenoWeight[which(type_index == j),i])
}
}
# aggregate canonical weight
CCWeight <- (Between_Discriminate_Ratio[1]/sum(Between_Discriminate_Ratio)) * BetweenOmicsWeight +
(Between_Discriminate_Ratio[2]/sum(Between_Discriminate_Ratio)) * OmicsPhenoWeight
# set row names
row.names(CCWeight) <- colnames(X_all)
return(CCWeight)
}
Ws <- getCCAout_Multi(list(X1,X2), Trait = as.matrix(Y), Lambda = c(0.2,0.2), NoTrait = FALSE, CCcoef = c(1,1,1))
# (INTERNAL)
myMultiCCA <- function(xlist, penalty=NULL, ws=NULL, niter=25,
type="standard", ncomponents=1, trace=TRUE,
standardize=TRUE, CCcoef = NULL){
# Perform sparse multiple canonical correlation analysis (SmCCA) for a list
#   of data inputs.
#
# xlist: A list of length K, where K is the number of data sets on which to
#   perform SmCCA. Dataset k should be a matrix of dimension $n \times p_k$,
#   where $p_k$ is the number of features in data set k. If some quantitative
#   phenotype information is included in the list, it should be the last
#   element of the list and of dimension $n \times 1$.
# penalty: The penalty terms to be used. Can be a single value (if the same
#   penalty term is to be applied to each data set) or a K-vector, indicating
#   a different penalty term for each data set. There are 2 possible
#   interpretations for the penalty term: If type = "standard" then this is
#   an L1 bound on $w_k$, and it must be between 1 and $\sqrt(p_k)$ ($p_k$ is
#   the number of features in matrix $X_k$). If type = "ordered" then this is
#   the parameter for the fussed lasso penalty on $w_k$.
# type: Either "standard" or "ordered" to indicate if the columns are
#   unordered or ordered. If type = "standard", then a lasso penalty is aplied
#   to v, to enforce sparsity. If type = "ordered" (generally used for CGH
#   data), then a fused lasso penalty is applied, to enforce both sparsity and
#   soothness. This argument can be a vector of lenght K (if different data
#   sets are of different types) or it can be a single value "standard" or
#   "ordered" (if all data sets are of the same type).
# ncomponents: Number of factors to output. Default is 1.
# niter: Number of iterations to be perfromed. Default is 25.
# ws: A list of length K. The kth element contains the first ncomponents
#   columns of the v matrix of the SVD of $X_k$. If NULL, then the SVD of
#   $X_1, ..., X_K$ will be computed inside the MultiCCA function. However,
#   if you plan to run this function multiple times, then save a copy of the
#   argument so that it does not need to be re-computed.
# trace: Logical. Whether to print out progress.
# standardize: Whether to center and scale the columns of $X_1, ..., X_K$.
#   Default is TRUE.
# CCcoef: Optional coefficients for the pairwise canonical correlations (CC).
#   If CCcoef = NULL (default), then the objective function is the total sum
#   of all pairwise CC. It can also be a coefficient vector that follows the
#   column order of combn(K, 2).
if(ncol(xlist[[length(xlist)]]) > 1){
out <- PMA::MultiCCA(xlist, penalty=penalty, ws=ws, niter=niter,
type=type, ncomponents=ncomponents, trace=ncomponents,
standardize=standardize)
}else{
# The Kth data set in xlist is a one dimensional phenotype
call <- match.call()
K <- length(xlist)
pair_CC <- utils::combn(K, 2)
num_CC <- ncol(utils::combn(K, 2))
# Check canonical correlation coefficients.
if(is.null(CCcoef)){CCcoef <- rep(1, num_CC)}
if(length(CCcoef) != num_CC){
stop(paste0("Invalid coefficients for pairwise canonical correlations.
Please provide ", num_CC, " numerical values for CCcoef.
Be sure to match combn(K,2) column order."))
}
# Check data type.
if(length(type)==1){# Expand a single type to a vector of length(xlist).
if(type != "standard"){
stop("The phenotype data must be continuous and follow the type 'standard'. ")
}
type <- rep(type, K)}
if(length(type)!=K){
stop("Type must be a vector of length 1, or length(xlist)")}
if(sum(type!="standard")>0){
stop("Each element of type must be standard and not ordered.")}
# Standardize or not.
if(standardize){xlist <- lapply(xlist, scale)}
# Initialize weights.
if(!is.null(ws)){
makenull <- FALSE
for(i in seq_len(K-1)){
if(ncol(ws[[i]])<ncomponents) makenull <- TRUE
}
if(makenull) ws <- NULL
}
if(is.null(ws)){
ws <- list()
for(i in seq_len(K-1)){
ws[[i]] <- matrix(svd(xlist[[i]])$v[,seq_len(ncomponents)], ncol=ncomponents)
}
ws[[K]] <- 1
}
ws.init <- ws
# Check penalties.
if(is.null(penalty)){
penalty <- rep(NA, K)
penalty[type=="standard"] <- 4 # this is the default value of sumabs
for(k in seq_len(K-1)){
if(type[k]=="ordered"){
stop("Current version requires all element types to be standard (not ordered).")
}
}
}
if(length(penalty)==1) penalty <- rep(penalty, K)
if(sum(penalty<1 & type=="standard")){
stop("Cannot constrain sum of absolute values of weights to be less than
1.")
}
for(i in seq_len(K-1)){
if(type[i]=="standard" && penalty[i]>sqrt(ncol(xlist[[i]]))){
stop("L1 bound of weights should be no more than sqrt of the number of
columns of the corresponding data set.", fill=TRUE)
}
}
ws.final <- ws.init
for(i in seq_len(K-1)){
ws.final[[i]] <- matrix(0, nrow=ncol(xlist[[i]]), ncol=ncomponents)
}
cors <- NULL
for(comp in seq_len(ncomponents)){
ws <- list()
for(i in seq_len(K-1)) ws[[i]] <- ws.init[[i]][,comp]
ws[[K]] <- 1
curiter <- 1
crit.old <- -10
crit <- -20
storecrits <- NULL
while(curiter<=niter && abs(crit.old-crit)/abs(crit.old)>.001 &&
crit.old!=0){
crit.old <- crit
crit <- myGetCrit(xlist, ws, pair_CC, CCcoef)
storecrits <- c(storecrits,crit)
if(trace) cat(curiter, fill=FALSE)
curiter <- curiter+1
for(i in seq_len(K-1)){
ws[[i]] <- myUpdateW(xlist, i, K, penalty[i], ws, type[i], ws.final,
pair_CC, CCcoef)
}
}
for(i in seq_len(K-1)) ws.final[[i]][,comp] <- ws[[i]]
cors <- c(cors, myGetCors(xlist, ws, pair_CC, CCcoef))
}
out <- list(ws=ws.final, ws.init=ws.init, K=K, call=call, type=type,
penalty=penalty, cors=cors)
class(out) <- "MultiCCA"
}
return(out)
}
# (INTERNAL)
myUpdateW <- function(xlist, i, K, sumabsthis, ws, type="standard", ws.final,
pair_CC, CCcoef){
# Update canonical weights for the ith data set.
#
# xlist: Data list.
# i: Data set index.
# K: Total number of data sets.
# sumabsthis: Penalty for the ith data set.
# ws: First ncomponents columns of the v matrix of the SVD of $X_k$'s.
# type: Type of data sets.
# ws.final: Current weight matrix.
# pair_CC: The output of combn(K, 2). A two-row table that include indices for
#   pairwise canonical correlaltions between members of xlist.
# CCcoef: Optional coefficients for the pairwise canonical correlations (CC).
tots0 <- vapply(seq_len(length(CCcoef)), function(x){
pairx <- pair_CC[ , x]
Xi <- xlist[[i]]
if(pairx[1] != i & pairx[[2]] != i){
y <- rep(0, ncol(Xi))
}else{
if(pairx[1] == i){j <- pairx[2]}
if(pairx[2] == i){j <- pairx[1]}
Xj <- xlist[[j]]
# diagmat is the diagonal correlation matrix calculated using previous
#   canonical directions.
# If phenotype is included, only the first canonical direction is used.
#   diagmat is therefore a zero matrix.
diagmat <- (t(ws.final[[i]])%*%t(Xi))%*%(Xj%*%ws.final[[j]])
diagmat[row(diagmat)!=col(diagmat)] <- 0
y <- t(Xi)%*%(Xj%*%ws[[j]]) -
ws.final[[i]]%*%(diagmat%*%(t(ws.final[[j]])%*%ws[[j]]))
y <- y * CCcoef[x]
}
return(y)
}, numeric(ncol(xlist[[i]])))
tots <- rowSums(tots0)
if(type=="standard"){
sumabsthis <- BinarySearch(tots, sumabsthis)
w <- soft(tots, sumabsthis)/l2n(soft(tots, sumabsthis))
} else {
stop("Current version requires all element types to be standard (not ordered).")
}
return(w)
}
# (INTERNAL)
myGetCrit <- function(xlist, ws, pair_CC, CCcoef){
# Compute the matrix form SmCCA objective function value for given weights.
#
# ws: First ncomponents columns of the v matrix of the SVD of $X_k$'s.
crits <- apply(pair_CC, 2, function(x){
i <- x[1]
j <- x[2]
y <- t(ws[[i]])%*%t(xlist[[i]])%*%xlist[[j]]%*%ws[[j]]
return(y)
})
crit <- sum(crits * CCcoef)
return(crit)
}
# (INTERNAL)
myGetCors <- function(xlist, ws, pair_CC, CCcoef){
# Compute total weighted canonical correlations for given weights.
#
# xlist: Data list.
# pair_CC: The output of combn(K, 2). A two-row table that include indices for
#   pairwise canonical correlaltions between members of xlist.
# CCcoef: Optional coefficients for the pairwise canonical correlations (CC).
CCs <- apply(pair_CC, 2, function(x){
i <- x[1]
j <- x[2]
y <- stats::cor(xlist[[i]]%*%ws[[i]], xlist[[j]]%*%ws[[j]])
if(is.na(y)){y <- 0}
return(y)
})
Cors <- sum(CCs * CCcoef)
return(Cors)
}
# (INTERNAL)
BinarySearch <- function(argu,sumabs){
#  Update sumabs so that the L1 norm of argu equals given penalty.
if(l2n(argu)==0 || sum(abs(argu/l2n(argu)))<=sumabs) return(0)
lam1 <- 0
lam2 <- max(abs(argu))-1e-5
iter <- 1
while(iter < 150){
su <- soft(argu,(lam1+lam2)/2)
if(sum(abs(su/l2n(su)))<sumabs){
lam2 <- (lam1+lam2)/2
} else {
lam1 <- (lam1+lam2)/2
}
if((lam2-lam1)<1e-6) return((lam1+lam2)/2)
iter <- iter+1
}
warning("Didn't quite converge")
return((lam1+lam2)/2)
}
# (INTERNAL)
l2n <- function(vec){
# Computes the L2 norm. If the norm is zero, set it to 0.05.
a <- sqrt(sum(vec^2))
if(a==0) a <- .05
return(a)
}
# (INTERNAL)
soft <- function(x,d){
# Soft thresholding.
return(sign(x)*pmax(0, abs(x)-d))
}
##################################################
##################################################
# Additional internal functions for ordered data #
##################################################
# Additional internal functions for ordered data #
##################################################
##################################################
# Additional internal functions for ordered data #
##################################################
# ChooseLambda1Lambda2()
Ws <- getCCAout_Multi(list(X1,X2), Trait = as.matrix(Y), Lambda = c(0.2,0.2), NoTrait = FALSE, CCcoef = c(1,1,1))
View(Ws)
getMultiOmicsCC(X = list(X1,X2), Y = as.matrix(Y),CCWeight =  Ws, CCcoef = c(1,1,1))
# Internal function to calculate the canonical correlation value for multi-omics setting.
getMultiOmicsCC <- function(X, CCcoef, CCWeight, Y)
{
# sort out all combinations
paircomb <- utils::combn(length(X), 2)
# projection
omics_projection <- purrr::map(1:length(X), function(xx){
X[[xx]] %*% CCWeight[[xx]]
})
omics_projection <- do.call(cbind, omics_projection)
# calculate correlation between omics projection
omics_cor <- stats::cor(omics_projection)
# only extract the upper triangle of correlation matrix
omics_cor <- omics_cor[upper.tri(omics_cor)]
# calculate canonical correlation (pairwise between-omics)
CCBetween <- sum(CCcoef[1:length(X)] * omics_cor)
# calculate canonical correlation (pairwise omics-phenotype)
pheno_cor <- sum(stats::cor(omics_projection, Y) * CCcoef[(length(X) + 1):length(CCcoef)])
# adding two components together
OverallCC <- omics_cor + pheno_cor
return(OverallCC)
}
getMultiOmicsCC(X = list(X1,X2), Y = as.matrix(Y),CCWeight =  Ws, CCcoef = c(1,1,1))
Ws <- getCCAout_Multi(list(X1,X2, X3), Trait = as.matrix(Y), Lambda = c(0.2,0.2, 0.2), NoTrait = FALSE, CCcoef = c(1,1,1))
X3 <- matrix(rnorm(60000,0,1), nrow = 200)
colnames(X3) <- paste('metabolite',1:300)
Ws <- getCCAout_Multi(list(X1,X2, X3), Trait = as.matrix(Y), Lambda = c(0.2,0.2, 0.2), NoTrait = FALSE, CCcoef = c(1,1,1))
Ws <- getCCAout_Multi(list(X1,X2, X3), Trait = as.matrix(Y), Lambda = c(0.2,0.2, 0.2), NoTrait = FALSE, CCcoef = rep(1,6))
getMultiOmicsCC(X = list(X1,X2), Y = as.matrix(Y),CCWeight =  Ws, CCcoef = c(1,1,1))
getMultiOmicsCC(X = list(X1,X2), Y = as.matrix(Y),CCWeight =  Ws, CCcoef = rep(1,6))
getMultiOmicsCC(X = list(X1,X2,X3), Y = as.matrix(Y),CCWeight =  Ws, CCcoef = rep(1,6))
View(Ws)
X = list(X1,X2,X3); Y = as.matrix(Y);CCWeight =  Ws;CCcoef = rep(1,6)
# sort out all combinations
paircomb <- utils::combn(length(X), 2)
# projection
omics_projection <- purrr::map(1:length(X), function(xx){
X[[xx]] %*% CCWeight[[xx]]
})
omics_projection <- do.call(cbind, omics_projection)
# calculate correlation between omics projection
omics_cor <- stats::cor(omics_projection)
# only extract the upper triangle of correlation matrix
omics_cor <- omics_cor[upper.tri(omics_cor)]
# calculate correlation between omics projection
omics_cor <- stats::cor(omics_projection)
View(omics_cor)
# only extract the upper triangle of correlation matrix
omics_cor <- omics_cor[upper.tri(omics_cor)]
# calculate correlation between omics projection
omics_cor <- stats::cor(omics_projection)
# only extract the upper triangle of correlation matrix
omics_cor <- omics_cor[upper.tri(omics_cor)]
# calculate canonical correlation (pairwise between-omics)
CCBetween <- sum(CCcoef[1:length(X)] * omics_cor)
# calculate canonical correlation (pairwise omics-phenotype)
pheno_cor <- sum(stats::cor(omics_projection, Y) * CCcoef[(length(X) + 1):length(CCcoef)])
# adding two components together
OverallCC <- omics_cor + pheno_cor
devtools::check()
evtools::build(args = "--compact-vignettes=gs+qpdf")
devtools::build(args = "--compact-vignettes=gs+qpdf")
library(SmCCNet)
combn(3,2)
combn(4,2)
combn(5,2)
apply(combn(4,2), 2, function(x){x[2] != 4})
devtools::build(args = "--compact-vignettes=gs+qpdf")
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::build(args = "--compact-vignettes=gs+qpdf")
library(SmCCNet)
devtools::build(args = "--compact-vignettes=gs+qpdf")
library(SmCCNet)
library(SmCCNet)
?getRobustPseudoWeights_Multi
devtools::build(args = "--compact-vignettes=gs+qpdf")
library(SmCCNet)
library(SmCCNet)
set.seed(12345)
X1 <- matrix(rnorm(60000,0,1), nrow = 200)
colnames(X1) <- paste('gene',1:300)
X2 <- matrix(rnorm(60000,0,1), nrow = 200)
colnames(X2) <- paste('protein',1:300)
Y <- matrix(rnorm(200,0,1), nrow = 200)
Y_binary <- rbinom(200,1,0.5)
covar <- matrix(rnorm(400,0,1), nrow = 200)
colnames(X1) <- paste0('gene_', 1:300)
colnames(X1) <- paste0('mirna_', 1:300)
result <- FastAutoSmCCNet(X = list(X1,X2), Y = Y, K = 5, subSampNum = 200,
preprocess = TRUE,
AdjustedCovar = covar,
DataType = c('Gene', 'miRNA'),
saving_dir = 'C:/Users/liux4/Documents')
data(X1)
library(SmCCNet)
data(ExampleData)
knitr::opts_chunk$set(echo = TRUE)
# randomly simulate data
library(SmCCNet)
X1 <- matrix(rnorm(60000,0,1), nrow = 200)
colnames(X1) <- paste('gene',1:300)
X2 <- matrix(rnorm(60000,0,1), nrow = 200)
colnames(X2) <- paste('protein',1:300)
Y <- matrix(rnorm(200,0,1), nrow = 200)
Y_binary <- rbinom(200,1,0.5)
covar <- matrix(rnorm(400,0,1), nrow = 200)
colnames(X1) <- paste0('gene_', 1:300)
colnames(X1) <- paste0('mirna_', 1:300)
# multi-omics CCA with covariate adjustment
result <- FastAutoSmCCNet(X = list(X1,X2), Y = Y, K = 5, subSampNum = 200,
preprocess = TRUE,
AdjustedCovar = covar,
DataType = c('Gene', 'miRNA'),
saving_dir = 'C:/Users/liux4/Documents')
sink("myfilename", append=FALSE, split=TRUE)
sink(
)
?choose
choose(70,5) * choose(25,1)
300000000/100000
300000000/500000
300000000/10000000
300000000/100000000
devtools::document()
devtools::build(args = "--compact-vignettes=gs+qpdf")
library(SmCCNet)
